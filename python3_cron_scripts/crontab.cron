# Edit this file to introduce tasks to be run by cron.
# 
# Each task to run has to be defined through a single line
# indicating with different fields when the task will be run
# and what command to run for the task
# 
# To define the time you can provide concrete values for
# minute (m), hour (h), day of month (dom), month (mon),
# and day of week (dow) or use '*' in these fields (for 'any').# 
# Notice that tasks will be started based on the cron's system
# daemon's notion of time and timezones.
# 
# Output of the crontab jobs (including errors) is sent through
# email to the user the crontab file belongs to (unless redirected).
# 
# For example, you can run a backup of all your user accounts
# at 5 a.m every week with:
# 0 5 * * 1 tar -zcf /var/backups/home.tgz /home/
# 
# For more information see the manual pages of crontab(5) and cron(8)
# 
# m h  dom mon dow   command

## This is an example cron script to show the order in which the scripts should be run.
## NOTE: The execution times associated with the example cron entries below are just random numbers.
## Please adjust the start times to fit your organization.

## Step 1: Collect information on the root domains (zones) for your organization from
## sources such as PassiveTotal or an internal source (Infoblox, UltraDNS, etc.).
## If these scripts do not apply to your environment, then root domains can also be manually
## added via the setup scripts or UI. Either way, all of the remaining scripts are dependent on
## knowing what root domains Marinus will be tracking.
0 2 * * 0 cd /your/directory/;/your/directory/get_passivetotal_data.py >> /your/directory/logs/passivetotal_data.log 2>&1
0 3 * * 0 cd /your/directory/;/your/directory/get_iblox_alpha_zones.py >> /your/directory/logs/get_iblox_alpha_zones.log 2>&1
0 4 * * 0 cd /your/directory/;/your/directory/get_ultradns_zones.py >> /your/directory/logs/get_ultradns_zones.log 2>&1
0 5 * * 0 cd /your/directory/;/your/directory/get_route53_domains.py >> /your/directory/logs/get_route53_domains.log 2>&1
0 6 * * 0 cd /your/directory/;/your/directory/fetch_azure_dns.py >> /your/directory/logs/fetch_azure_dns.log 2>&1


## Step 2: Collect DNS records (A, MX, TXT, etc.) from any internal sources such as Infoblox, UltraDNS, Amazon, Azure, etc.
## This can be skipped if you do not have access to your internal DNS infrastructure.
## However, it is encouraged to complement the external data with internal data.
## Infoblox users would use all of the get_iblox_* scripts and the get_infoblox_*_extattrs scripts.
## UltraDNS users should run the get_ultradns_zones_info script.
0 3 * * 0 cd /your/directory/;/your/directory/get_iblox_host.py >> /your/directory/logs/iblox_host.log 2>&1
0 3 * * 0 cd /your/directory/;/your/directory/get_infoblox_a_extattrs.py >> /your/directory/logs/get_infoblox_a_extattrs.log 2>&1
0 2 * * 0 cd /your/directory/;/your/directory/get_ultradns_zones_info.py >> /your/directory/logs/get_ultradns_zones_info.log 2>&1


## Step 3a: Check third-parties such as VirusTotal, Certicate Transparency Logs, Rapid7 OpenData, Common Crawl, etc.
## Some of these scripts may need to be run on separate instances due to the size of the files that they process.
## This is not a complete list of all the scripts that can be run in this phase.
0 12 * * 4 cd /your/directory/;/your/directory/get_virustotal_data.py >> /your/directory/logs/virustotal_data.log 2>&1
0 12 20 * * cd /your/directory/ct_scripts;/your/directory/ct_scripts/download_digicert_certs.py >> /your/directory/ct_scripts/logs/digicert_certs.log 2>&1
50 02 * * * cd /your/directory/;/your/directory/get_sonar_data_unified.py --sonar_file_type rdns >> /your/directory /logs/sonar_data.log 2>&1
25 16 * * * cd /your/directory/;/your/directory/get_data_by_cidr_unified.py --sonar_file_type dns >> /your/directory/logs/sonar_cidr_data.log 2>&1
0 1 * * * cd /your/directory/;/your/directory/common_crawl_graph.py >> /your/directory/logs/common_crawl_graph.log 2>&1
0 11 * * 1 cd /your/directory/;/your/directory/whois_lookups.py >> /your/directory/logs/whois_lookups.log 2>&1
00 1 */2 * * cd /your/directory/;/your/directory/get_censys_files.py >> /your/directory/logs/get_files.log 2>&1
30 12 * * * cd /your/directory/;/your/directory/search_censys_files_new.py >> /your/directory/logs/search_files.log 2>&1
30 14 * * 5 cd /your/directory/;/your/directory/get_crt_sh.py --fetch_dns_records --download_methods dbAndSave --cert_save_location /your/directory/cert_sh_files >> /your/directory/logs/crt_sh.log 2>&1

# Do this step for each individual CT log that you want to manually search. Replace YOUR_LOG_NAME with the logs you want to directly query.
30 14 * * 6 cd /your/directory/;/your/directory/get_original_ct_logs.py --download_methods dbAndSave --cert_save_location /your/directory/cert_sh_files --log_source YOUR_LOG_NAME --save_type PEM >> /your/directory/logs/ct_YOUR_LOG_NAME.log 2>&1



## Step 3b: (Optional) Collect your own scan data using zgrab scripts to scan your networks
08 00 * * 1 cd /your/directory/;/your/directory/zgrab_http_domain.py -p80 >> /your/directory/logs/zgrab_domain_80.log 2>&1
09 00 * * 5 cd /your/directory/;/your/directory/zgrab_port_ip.py -p443 >> /your/directory/logs/zgrab_port_443.log 2>&1


## Step 4: Do a recursive round on the data that you have collected to find additional DNS records.
## This includes checking sources inside of certificates, second passes on existing records, etc.
0 23 * * 1 cd /your/directory/;/your/directory/sonar_round_two.py >> /your/directory/logs/sonar_round_two.log 2>&1
10 23 * * 1 cd /your/directory/;/your/directory/extract_vt_names.py >> /your/directory/logs/extract_vt_names.log 2>&1
0 1 * * 2 cd /your/directory/;/your/directory/extract_ssl_names.py >> /your/directory/logs/extract_ssl_names.log 2>&1
0 3 * * 6 cd /your/directory/;/your/directory/marinus_dns.py >> /your/directory/logs/marinus_dns.log 2>&1


## Step 5: Collect information on third-party networks, such as AWS and Azure, to make them easier to identify
## IP addresses within their range.
0 10 * * 1 cd /your/directory/;/your/directory/get_aws_data.py >> /your/directory/logs/aws_data.log 2>&1
15 10 * * 1 cd /your/directory/;/your/directory/get_azure_data.py >> /your/directory/logs/azure_data.log 2>&1
30 10 * * * cd /your/directory/;/your/directory/upload_akamai_data.py >> /your/directory/logs/akamai_data.log 2>&1


## Step 6: Identify the records which are pointing to third-party domains
0 4 * * 2 cd /your/directory/;/your/directory/get_external_cnames.py >> /your/directory/logs/get_external_cnames.log 2>&1


## Step 7: Create d3.js graphs based on the data that you have collected.
## This would be the last step in the process once you have as much data as possible.
## The prior scipts do not necessarily have to becompletely finished.
## These scripts will work with whatever they have at the time that they start.
0 1 * * 3 cd /your/directory/;/your/directory/create_tpd_graphs.py >> /your/directory/logs/create_tpd_graphs.log 2>&1
0 8 * * 3 cd /your/directory/;/your/directory/create_graphs2.py >> /your/directory/logs/create_graphs2.log 2>&1
0 12 * * 3 cd /your/directory/;/your/directory/create_netaddr_graphs.py >> /your/directory/logs/create_netaddr_graphs.log 2>&1
0 10 * * 4 cd /your/directory/;/your/directory/create_cert_graphs.py --check_ct_scans --check_443_scans >> /your/directory/logs/create_cert_graphs.log 2>&1


## Step 8: Do maintenance on the database such as removing old records
30 10 * * 1 cd /your/directory/;/your/directory/remove_fixed_dead_dns_records.py >> /your/directory/logs/remove_dead_dns.log 2>&1


## Maintenance scripts to get rid of old records and update dead DNS records
50 10 * * * cd /your/directory/;/your/directory/remove_expired_entries.py >> /your/directory/logs/remove_expired.log 2>&1
30 10 * * 1 cd /mnt/data/py3v2/;/mnt/data/py3v2/remove_fixed_dead_dns_records.py >> /mnt/data/py3v2/logs/remove_dead_dns.log 2>&1


## (Optional) Run these scripts daily if you are using a secondary remote database.
## These can be skipped if you are able to run everything from a single environment.
0 10 * * * cd /your/directory/;/your/directory/download_from_remote_database.py >> /your/directory/logs/download_remote.log 2>&1
20 7 * * * cd /your/directory/;/your/directory/send_remote_server.py >> /your/directory/logs/send_remote_server.log 2>&1
